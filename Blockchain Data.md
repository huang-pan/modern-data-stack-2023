SubQuery

- https://www.youtube.com/watch?v=7YGR6pBJ0wI 
- Open source blockchain indexer
![thumbnail (1)](https://github.com/huang-pan/modern-data-stack-2023/assets/10567714/56d66a50-a1aa-495d-997e-673d862d6fe5)

Notes
- European DiD https://www.youtube.com/watch?v=ynNOCK61Lzw 
- 
- See blockchain university notes and lectures
- https://github.com/hyperledger/blockchain-explorer
- https://github.com/blockchain/?q=kotlin&type=&language=
- https://github.com/smartcontractkit
- 
- BTC https://github.com/bitcoinbook/bitcoinbook by Aantonop
	- Bitcoin core: stores blockchain on disk
	- Sha256 hash function: used by bitcoin
	- Nonce: number used once, increment
	- P2P
		- gossip protocol
	- BTC blocks store merkle trees of transactions
		- block size limits to ? MB?
	- transactions: input / output addresses
		- event based blockchain --> like event source microservices --> create state from events
		- transaction fees
	- mempool with UTXOs unspent transactions
	- miners pay themselves from coinbase
		- difficulty scaling periods
	- public + private key = transaction signature
		- Bitcoin uses Elliptic Curve Cryptography (ECC), ECC provides use of smaller sized keys than non-ECC techniques
	- Bitcoin scripting: like assembly language for CPUs, but for bitcoin
	- Elasticsearch: 30 GB BTC blockchain to 220 GB elasticsearch DB
- ETH
	- blockchain: Data structures are stored in Merkle Patricia tries (read this and this), usually inside a LevelDBstore (fast key value database)
	- https://medium.com/validitylabs/how-to-interact-with-the-ethereum-blockchain-and-create-a-database-with-python-and-sql-3dcbd579b3c0
		- get data from local node or hosted node (Infura)
	- unlike BTC, ETH has accounts that store account values
		- unifying utxo blockchains with account based blockchains (paper) https://eprint.iacr.org/2018/262.pdf 
	- Solidity programming language
	- Mix desktop IDE --> Remix online IDE
- Block data from node
	- https://bitcoindev.network/bitcoin-analytics-using-google-bigquery/
		- The bitcoin core client software currently stores various bits of data as on disk which has been optimised for the running and execution when hosting a bitcoin node. The structure in which this is data is stored however is in a normalised form and optimised for the running of the node, not for reporting purposes.
		- Although there are many ways in which we can extract and report on this data, this tutorial we will be looking into Google's denormalised data set which is frequently updated and has been optimised for reporting.
- GCP
	- Types of managed database services https://blog.yugabyte.com/new-to-google-cloud-databases-5-areas-of-confusion-that-you-better-be-aware-of/
		- Need for horizontal write scalability either in the same region or across multiple regions is the single driver for choosing Cloud Spanner over Cloud SQL. 
		- pick BigTable for single-region analytics use cases and Spanner for multi-region operational use cases.
	- https://cloud.google.com/bigtable
		- Bigquery to bigtable or Spanner using google dataflow https://cloud.google.com/dataflow
	- Bigquery https://cloud.google.com/solutions/bigquery-data-warehouse
		- How to guides https://cloud.google.com/bigquery/docs/how-to
			- automatically caches queries into temp tables https://cloud.google.com/bigquery/docs/cached-results
		- Project.dataset.table
		- monitoring https://cloud.google.com/bigquery/docs/monitoring
		- Designing schema: Follow these general guidelines to design the optimal schema for BigQuery:
			- Denormalize a dimension table that is larger than 10 gigabytes, unless you see strong evidence that data manipulation,  UPDATE and DELETE operation, costs outweigh the benefits of optimal queries.
			- Keep a dimension table that is smaller than 10 gigabytes normalized, unless the table rarely goes through UPDATEand DELETE operations.
			- Take full advantage of nested and repeated fields in denormalized tables.
		- BigQuery is essentially an analytical engine. It supports DML actions, but it isn't meant to be used as an online transaction processing (OLTP) store.
		- To speed up queries, avoid joins, create flattened tables (searchable columns)
		- BigQuery supports partitioning tables by date.
		- Has section on how to handle table schema updates, slowly changing dimension
		- Query optimization: Each time BigQuery executes a query, it executes a full-column scan. BigQuery doesn't use or support indexes. Because BigQuery performance and query costs are based on the amount of data scanned during a query, design your queries so that they reference only the columns that are relevant to the query. When using date-partitioned tables, ensure only the relevant partitions are scanned. You can achieve this by using partition filters based on PARTITIONTIME or PARTITIONDATE.
	- bigquery BI engine https://cloud.google.com/bi-engine/docs/introduction
		- BigQuery BI Engine is a fast, in-memory analysis service. By using BI Engine you can analyze data stored in BigQuery with sub-second query response time and with high concurrency.
		- only works with Google Data Studio
- Blockchain ETL
	- https://github.com/blockchain-etl
		- has Airflow DAGs, use with Cloud Composer
- Public blockchain datasets
	- https://cloud.google.com/blog/products/data-analytics/introducing-six-new-cryptocurrencies-in-bigquery-public-datasets-and-how-to-analyze-them?fbclid=IwAR1l8tsW8r5bXbyA7M7pz6yYXbUiGPA7np0czQxowN_whlBFgbACoXId8WU
		- THIS IS HOW GOOGLE STRUCTURES BLOCKCHAIN DATASETS!!!
			- standardized double entry booking system for many crypto blockchains
			- Bitcoin-like datasets (Bitcoin, Bitcoin Cash, Dash, Dogecoin, Litecoin and Zcash) together because they all have similar implementations, i.e., their source code is derived from Bitcoin’s. 
			- Similarly, we’re also releasing the Ethereum Classic dataset alongside the previously published Ethereum dataset, and Ethereum Classic is also using the same common schema.
		- A unified data ingest architecture
			- All datasets update every 24 hours via a common codebase, the Blockchain ETLingestion framework (built with Cloud Composer, previously described here), to accommodate a variety of Bitcoin-like cryptocurrencies. While this means higher latency for loading Bitcoin blocks into BigQuery, it also means that: We are able to ingest additional BigQuery datasets with less effort, meaning additional datasets can be onboarded more quickly in the future.
			- We can implement a low-latency loading solution once that can be used to enable real-time streaming transactions for all blockchains.
		- Unified schema and views
			- Since we provided the original Bitcoin dataset last year, we’ve learned how users want to access data, and restructured the dataset accordingly. Some of these changes address performance and convenience concerns, yielding faster and lower cost queries (commonly accessed nested data are denormalized; each table is partitioned by time).
		- Address classification
			- Blockchain transaction history can be aggregated by address and used to analyze user behavior. To motivate further exploration, we present a simple classifier that can detect Bitcoin mining pools.
		- google public dataset bigquery-public-data.crypto_bitcoin.transactions 
			- the language in the BigQuery table is a bit confusing- I added some more context in italics:
				- sender: input.addresses: Addresses which own the spent output (prior to transaction being mined)
				- receiver: output.addresses: Addresses which own this output (after the transaction is mined)
				- since the input addresses own the output prior to the transaction being mined, we label them as senders.  
				- similarly since the output addresses receive the output after the transaction is mined we label them as receivers. this helpful when unifying utxo blockchains with account based blockchains (paper) https://eprint.iacr.org/2018/262.pdf
			- in bigquery-public-data.crypto_bitcoin.transactions , transaction table represents arrows between transaction blocks
				- 
	- https://cloud.google.com/blog/products/gcp/bitcoin-in-bigquery-blockchain-analytics-on-public-data
		- dataset updates every 10 minutes.
		- biqquery UNNEST https://cloud.google.com/bigquery/docs/reference/standard-sql/arrays
	- https://bitcoindev.network/bitcoin-analytics-using-google-bigquery/
		- The bitcoin core client software currently stores various bits of data as on disk which has been optimised for the running and execution when hosting a bitcoin node. The structure in which this is data is stored however is in a normalised form and optimised for the running of the node, not for reporting purposes.
		- Although there are many ways in which we can extract and report on this data, this tutorial we will be looking into Google's denormalised data set which is frequently updated and has been optimised for reporting.
	- https://medium.com/google-cloud/analysing-1-2m-mainnet-contracts-in-20-seconds-using-eveem-and-bigquery-f69b6d66c7b2
- blockchain explorer
	- https://www.softwaretestinghelp.com/blockchain-explorer-tutorial/
		- Main use of explorer is for information verification
		- Above article shows how blockchain explorers work
			- Blockchain explorers work by using a database that holds all blockchain in a searchable format and tables. An explorer will, therefore, work with a node interface to first extract all the data in a given blockchain. Once it derives the data, it then stores it in easily searchable tables.
			- It will gather the latest transactions and blocks and arrange them according to the defined searchable categories – for instance, wallet addresses transaction IDs, rich lists, balances, etc
		- Blockchain explorers are the Google of cryptocurrencies and blockchain. They allow users to access different details related to transactions on specific wallet addresses and blockchains including amount transacted, sources and destination of funds, and status of the transactions.
		- They can be used to extract virtually any data related to transactions, wallets, and blockchains including rich lists and hidden messages.
		- #1) Explore the transaction history of any wallet address: This allows us to audit any wallet address and improves transparency on a blockchain.
		- #2) Explore receiving addresses and change addresses: In addition to the transaction receiving address, you can see the change address, which is an output that returns crypto to the spender to prevent too much of the input value from going to the transaction fees. This also improves the transparency of transactions.
		- #3) Explore the largest transaction of the day: This is supported by some explorers.
		- #4) Explore Mempool status: This allows us to explore the unconfirmed transactions on a blockchain including their details.
		- #5) Explore double-spend incidents: Some explorers support the discovery of how many double-spend transactions are taking place in a blockchain.
		- #6) Explore orphaned and stale blocks: These are blocks that are not attached to the longest blockchain even after mining and their parent blockchain is unknown. Stale blocks are those whose parents are known but still aren’t attached to the longest known chain. Some explorers allow us to see how many of these blocks were realized in a blockchain.
		- #7) Explore the pool or person who found or mined a particular block: Different individuals and mining pools (groups that combine their computing resources to mine crypto) compete to mine blocks in any given blockchain and explorers allow us to find who successfully mined a given block defined by its height.
		- #8) Explore genesis blocks: You can find the block that was mined first on a given chain, by whom as well as its other data.
		- #9) Allows users to see fees of transactions, blockchain difficulty, hash rate, and other data.
	- https://thegraph.com
		- ETH Graph DB / GraphQL blockchain explorer
	- https://medium.com/alethio/the-future-of-alethio-c4fd511e4c03  Under the Codefi Data, the following APIs are available:
		- Fundamental API — Query low-level blockchain data and state as well as token balances, transactions and DeFi charts. This API is an updated version of the former Alethio API. Read the documentation here
		- DeFi Graph API — Query current and historical metrics across all lending protocols including rates, locked value, originations, collateralization ratios and more. Read the documentation here
		- DeFi Score API — Query DeFi Score and associated risk metrics on all the DeFi Lending Protocols. Used for display in your wallet/dapp, research, or media content. Read the documentation here
- Smart contract analyzer
	- ETH https://medium.com/google-cloud/analysing-1-2m-mainnet-contracts-in-20-seconds-using-eveem-and-bigquery-f69b6d66c7b2

